{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data/btc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "data = dataset\n",
    "tek_ind_1 = copy.deepcopy(data)\n",
    "tek_ind_2 = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tek_ind_1['daily_return'] = tek_ind_1.close.pct_change().fillna(0) # Percentage change between the current and a prior element\n",
    "tek_ind_1['cum_daily_return'] = (1 + tek_ind_1['daily_return']).cumprod() # Cummulative Product (+1 is used not so we can ignore the 0s in the first couple rows)\n",
    "\n",
    "tek_ind_1['H-L'] = tek_ind_1.high - dataset.low\n",
    "\n",
    "tek_ind_1['C-O'] = tek_ind_1.close - tek_ind_1.open\n",
    "\n",
    "tek_ind_1['10day Ma'] = tek_ind_1.close.shift(1).rolling(window = 10).mean().fillna(0)\n",
    "tek_ind_1['50day Ma'] = tek_ind_1.close.shift(1).rolling(window = 50).mean().fillna(0)\n",
    "tek_ind_1['200day Ma'] = tek_ind_1.close.shift(1).rolling(window = 200).mean().fillna(0)\n",
    "\n",
    "import talib\n",
    "tek_ind_1['rsi'] = talib.RSI(tek_ind_1.close.values, timeperiod = 14)\n",
    "\n",
    "tek_ind_1['williams %R'] = talib.WILLR(tek_ind_1.high.values,\n",
    "                                       tek_ind_1.low.values, \n",
    "                                      tek_ind_1.close.values, \n",
    "                                      14)\n",
    "\n",
    "# create 7 and 21 days Moving Average\n",
    "tek_ind_1['ma7'] = tek_ind_1.close.rolling(window=7).mean().fillna(0)\n",
    "tek_ind_1['ma21'] = tek_ind_1.close.rolling(window=21).mean().fillna(0)\n",
    "\n",
    "# creating MACD\n",
    "tek_ind_1['ema_26'] = tek_ind_1.close.ewm(span=26).mean().fillna(0)\n",
    "tek_ind_1['ema_12'] = tek_ind_1.close.ewm(span=12).mean().fillna(0)\n",
    "tek_ind_1['macd'] = (tek_ind_1['ema_12'] - tek_ind_1['ema_26'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bollinger Bands\n",
    "#Set number of days and standard deviation to use for rolling lookback period for bollinger band calculation\n",
    "window = 21\n",
    "no_of_std =2\n",
    "\n",
    "#calculate rolling mean and standard deviation using number of days set above\n",
    "rolling_mean = tek_ind_1.close.rolling(window).mean()\n",
    "rolling_std = tek_ind_1.close.rolling(window).std()\n",
    "\n",
    "#create two new DF column to hold values of upper and lower Bollinger bands\n",
    "tek_ind_1['bb_high'] =(rolling_mean + (rolling_std * no_of_std)).fillna(0)\n",
    "tek_ind_1['bb_low'] =(rolling_mean - (rolling_std * no_of_std)).fillna(0)\n",
    "\n",
    "#create exponental moving average\n",
    "tek_ind_1['ema'] = tek_ind_1.close.ewm(com=0.5).mean()\n",
    "\n",
    "#create momentum\n",
    "tek_ind_1['momentum'] = tek_ind_1.close - 1\n",
    "\n",
    "# tek_ind_1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.plot(tek_ind_1['close'], label ='Actual')\n",
    "# plt.plot(tek_ind_1['bb_high'], label ='BBHigh')\n",
    "# plt.plot(tek_ind_1['bb_low'], label ='BBLow')\n",
    "# plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3451 entries, 0 to 3450\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   close             3451 non-null   float64\n",
      " 1   high              3451 non-null   float64\n",
      " 2   low               3451 non-null   float64\n",
      " 3   open              3451 non-null   float64\n",
      " 4   daily_return      3451 non-null   float64\n",
      " 5   cum_daily_return  3451 non-null   float64\n",
      " 6   H-L               3451 non-null   float64\n",
      " 7   C-O               3451 non-null   float64\n",
      " 8   10day Ma          3451 non-null   float64\n",
      " 9   50day Ma          3451 non-null   float64\n",
      " 10  200day Ma         3451 non-null   float64\n",
      " 11  rsi               3451 non-null   float64\n",
      " 12  williams %R       3451 non-null   float64\n",
      " 13  ma7               3451 non-null   float64\n",
      " 14  ma21              3451 non-null   float64\n",
      " 15  ema_26            3451 non-null   float64\n",
      " 16  ema_12            3451 non-null   float64\n",
      " 17  macd              3451 non-null   float64\n",
      " 18  bb_high           3451 non-null   float64\n",
      " 19  bb_low            3451 non-null   float64\n",
      " 20  ema               3451 non-null   float64\n",
      " 21  momentum          3451 non-null   float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 593.3 KB\n"
     ]
    }
   ],
   "source": [
    "tek_ind_1_copy = copy.deepcopy(tek_ind_1)\n",
    "tek_ind_1_copy = tek_ind_1_copy.fillna(0).drop(columns=['date', 'volume', 'adjClose', 'adjHigh','adjLow','adjOpen', 'adjVolume', 'divCash', 'splitFactor'])\n",
    "\n",
    "tek_ind_1_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0900000e+01, 1.0900000e+01, 1.0900000e+01, ..., 0.0000000e+00,\n",
       "        1.0900000e+01, 9.8999996e+00],\n",
       "       [1.1690000e+01, 1.1850000e+01, 1.1150000e+01, ..., 0.0000000e+00,\n",
       "        1.1492500e+01, 1.0690000e+01],\n",
       "       [1.1700000e+01, 1.1700000e+01, 1.1700000e+01, ..., 0.0000000e+00,\n",
       "        1.1636154e+01, 1.0700000e+01],\n",
       "       ...,\n",
       "       [4.5172973e+04, 4.6649246e+04, 4.3020789e+04, ..., 4.1751121e+04,\n",
       "        4.5576902e+04, 4.5171973e+04],\n",
       "       [4.9597684e+04, 4.9796078e+04, 4.4981742e+04, ..., 4.2134691e+04,\n",
       "        4.8257422e+04, 4.9596684e+04],\n",
       "       [4.8462754e+04, 5.0206160e+04, 4.7063383e+04, ..., 4.2345035e+04,\n",
       "        4.8394309e+04, 4.8461754e+04]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = tek_ind_1_copy.values.astype('float32')\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  -5185.0405\n",
      "Max:  60030.39\n"
     ]
    }
   ],
   "source": [
    "print (\"Min: \", np.min(values))\n",
    "print (\"Max: \", np.max(values))\n",
    "values = pd.DataFrame(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.450000</td>\n",
       "      <td>-0.050633</td>\n",
       "      <td>0.206422</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>2.826000</td>\n",
       "      <td>3.877000</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>2.577143</td>\n",
       "      <td>3.036667</td>\n",
       "      <td>3.113666</td>\n",
       "      <td>2.721575</td>\n",
       "      <td>-0.392091</td>\n",
       "      <td>3.954803</td>\n",
       "      <td>2.118531</td>\n",
       "      <td>2.304783</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>2.530000</td>\n",
       "      <td>0.151111</td>\n",
       "      <td>0.237615</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>2.721000</td>\n",
       "      <td>3.824000</td>\n",
       "      <td>...</td>\n",
       "      <td>-69.090912</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.971905</td>\n",
       "      <td>3.074723</td>\n",
       "      <td>2.701333</td>\n",
       "      <td>-0.373390</td>\n",
       "      <td>3.807623</td>\n",
       "      <td>2.136187</td>\n",
       "      <td>2.494928</td>\n",
       "      <td>1.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>0.158301</td>\n",
       "      <td>0.275229</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>2.645000</td>\n",
       "      <td>3.762600</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.818182</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.948095</td>\n",
       "      <td>3.069168</td>\n",
       "      <td>2.747282</td>\n",
       "      <td>-0.321886</td>\n",
       "      <td>3.748361</td>\n",
       "      <td>2.147830</td>\n",
       "      <td>2.831643</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.252294</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>3.709400</td>\n",
       "      <td>...</td>\n",
       "      <td>-96.078430</td>\n",
       "      <td>2.555714</td>\n",
       "      <td>2.921905</td>\n",
       "      <td>3.045446</td>\n",
       "      <td>2.747700</td>\n",
       "      <td>-0.297746</td>\n",
       "      <td>3.709702</td>\n",
       "      <td>2.134107</td>\n",
       "      <td>2.777214</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2.770000</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>2.770000</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.254128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.638000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>...</td>\n",
       "      <td>-95.921570</td>\n",
       "      <td>2.594286</td>\n",
       "      <td>2.895238</td>\n",
       "      <td>3.024979</td>\n",
       "      <td>2.751131</td>\n",
       "      <td>-0.273848</td>\n",
       "      <td>3.662665</td>\n",
       "      <td>2.127811</td>\n",
       "      <td>2.772405</td>\n",
       "      <td>1.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>46294.660156</td>\n",
       "      <td>48436.054688</td>\n",
       "      <td>44101.605469</td>\n",
       "      <td>47081.562500</td>\n",
       "      <td>-0.016641</td>\n",
       "      <td>4247.216309</td>\n",
       "      <td>4334.447754</td>\n",
       "      <td>-786.906006</td>\n",
       "      <td>52178.921875</td>\n",
       "      <td>40734.160156</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.615631</td>\n",
       "      <td>51331.933594</td>\n",
       "      <td>48664.531250</td>\n",
       "      <td>46607.777344</td>\n",
       "      <td>49568.195312</td>\n",
       "      <td>2960.416748</td>\n",
       "      <td>58266.695312</td>\n",
       "      <td>39062.367188</td>\n",
       "      <td>46891.851562</td>\n",
       "      <td>46293.660156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3447</th>\n",
       "      <td>46131.218750</td>\n",
       "      <td>48388.878906</td>\n",
       "      <td>45010.531250</td>\n",
       "      <td>46284.902344</td>\n",
       "      <td>-0.003530</td>\n",
       "      <td>4232.222168</td>\n",
       "      <td>3378.345947</td>\n",
       "      <td>-153.682755</td>\n",
       "      <td>51893.777344</td>\n",
       "      <td>40871.097656</td>\n",
       "      <td>...</td>\n",
       "      <td>-85.762161</td>\n",
       "      <td>49943.273438</td>\n",
       "      <td>48994.253906</td>\n",
       "      <td>46572.476562</td>\n",
       "      <td>49039.429688</td>\n",
       "      <td>2466.952148</td>\n",
       "      <td>57662.570312</td>\n",
       "      <td>40325.937500</td>\n",
       "      <td>46384.761719</td>\n",
       "      <td>46130.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>45172.972656</td>\n",
       "      <td>46649.246094</td>\n",
       "      <td>43020.789062</td>\n",
       "      <td>46127.402344</td>\n",
       "      <td>-0.020772</td>\n",
       "      <td>4144.309570</td>\n",
       "      <td>3628.455566</td>\n",
       "      <td>-954.430298</td>\n",
       "      <td>51293.832031</td>\n",
       "      <td>40981.621094</td>\n",
       "      <td>...</td>\n",
       "      <td>-85.966362</td>\n",
       "      <td>48193.121094</td>\n",
       "      <td>49297.121094</td>\n",
       "      <td>46468.808594</td>\n",
       "      <td>48444.589844</td>\n",
       "      <td>1975.779541</td>\n",
       "      <td>56843.125000</td>\n",
       "      <td>41751.121094</td>\n",
       "      <td>45576.902344</td>\n",
       "      <td>45171.972656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>49597.683594</td>\n",
       "      <td>49796.078125</td>\n",
       "      <td>44981.742188</td>\n",
       "      <td>45167.027344</td>\n",
       "      <td>0.097950</td>\n",
       "      <td>4550.246094</td>\n",
       "      <td>4814.334473</td>\n",
       "      <td>4430.654785</td>\n",
       "      <td>50654.812500</td>\n",
       "      <td>41082.343750</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.114357</td>\n",
       "      <td>47551.691406</td>\n",
       "      <td>49487.710938</td>\n",
       "      <td>46700.578125</td>\n",
       "      <td>48621.988281</td>\n",
       "      <td>1921.410034</td>\n",
       "      <td>56840.734375</td>\n",
       "      <td>42134.691406</td>\n",
       "      <td>48257.421875</td>\n",
       "      <td>49596.683594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>48462.753906</td>\n",
       "      <td>50206.160156</td>\n",
       "      <td>47063.382812</td>\n",
       "      <td>49601.929688</td>\n",
       "      <td>-0.022883</td>\n",
       "      <td>4446.124023</td>\n",
       "      <td>3142.775635</td>\n",
       "      <td>-1139.177368</td>\n",
       "      <td>50022.539062</td>\n",
       "      <td>41311.078125</td>\n",
       "      <td>...</td>\n",
       "      <td>-64.514839</td>\n",
       "      <td>47490.218750</td>\n",
       "      <td>49583.476562</td>\n",
       "      <td>46831.109375</td>\n",
       "      <td>48597.492188</td>\n",
       "      <td>1766.380859</td>\n",
       "      <td>56821.921875</td>\n",
       "      <td>42345.035156</td>\n",
       "      <td>48394.308594</td>\n",
       "      <td>48461.753906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3381 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3         4   \\\n",
       "70        2.250000      3.000000      2.250000      2.450000 -0.050633   \n",
       "71        2.590000      2.590000      2.460000      2.530000  0.151111   \n",
       "72        3.000000      3.000000      2.540000      2.540000  0.158301   \n",
       "73        2.750000     15.000000      2.500000      2.500000 -0.083333   \n",
       "74        2.770000      2.770000      2.770000      2.770000  0.007273   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "3446  46294.660156  48436.054688  44101.605469  47081.562500 -0.016641   \n",
       "3447  46131.218750  48388.878906  45010.531250  46284.902344 -0.003530   \n",
       "3448  45172.972656  46649.246094  43020.789062  46127.402344 -0.020772   \n",
       "3449  49597.683594  49796.078125  44981.742188  45167.027344  0.097950   \n",
       "3450  48462.753906  50206.160156  47063.382812  49601.929688 -0.022883   \n",
       "\n",
       "               5            6            7             8             9   ...  \\\n",
       "70       0.206422     0.750000    -0.200000      2.826000      3.877000  ...   \n",
       "71       0.237615     0.130000     0.060000      2.721000      3.824000  ...   \n",
       "72       0.275229     0.460000     0.460000      2.645000      3.762600  ...   \n",
       "73       0.252294    12.500000     0.250000      2.610000      3.709400  ...   \n",
       "74       0.254128     0.000000     0.000000      2.638000      3.650000  ...   \n",
       "...           ...          ...          ...           ...           ...  ...   \n",
       "3446  4247.216309  4334.447754  -786.906006  52178.921875  40734.160156  ...   \n",
       "3447  4232.222168  3378.345947  -153.682755  51893.777344  40871.097656  ...   \n",
       "3448  4144.309570  3628.455566  -954.430298  51293.832031  40981.621094  ...   \n",
       "3449  4550.246094  4814.334473  4430.654785  50654.812500  41082.343750  ...   \n",
       "3450  4446.124023  3142.775635 -1139.177368  50022.539062  41311.078125  ...   \n",
       "\n",
       "              12            13            14            15            16  \\\n",
       "70   -100.000000      2.577143      3.036667      3.113666      2.721575   \n",
       "71    -69.090912      2.590000      2.971905      3.074723      2.701333   \n",
       "72    -31.818182      2.590000      2.948095      3.069168      2.747282   \n",
       "73    -96.078430      2.555714      2.921905      3.045446      2.747700   \n",
       "74    -95.921570      2.594286      2.895238      3.024979      2.751131   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "3446  -84.615631  51331.933594  48664.531250  46607.777344  49568.195312   \n",
       "3447  -85.762161  49943.273438  48994.253906  46572.476562  49039.429688   \n",
       "3448  -85.966362  48193.121094  49297.121094  46468.808594  48444.589844   \n",
       "3449  -57.114357  47551.691406  49487.710938  46700.578125  48621.988281   \n",
       "3450  -64.514839  47490.218750  49583.476562  46831.109375  48597.492188   \n",
       "\n",
       "               17            18            19            20            21  \n",
       "70      -0.392091      3.954803      2.118531      2.304783      1.250000  \n",
       "71      -0.373390      3.807623      2.136187      2.494928      1.590000  \n",
       "72      -0.321886      3.748361      2.147830      2.831643      2.000000  \n",
       "73      -0.297746      3.709702      2.134107      2.777214      1.750000  \n",
       "74      -0.273848      3.662665      2.127811      2.772405      1.770000  \n",
       "...           ...           ...           ...           ...           ...  \n",
       "3446  2960.416748  58266.695312  39062.367188  46891.851562  46293.660156  \n",
       "3447  2466.952148  57662.570312  40325.937500  46384.761719  46130.218750  \n",
       "3448  1975.779541  56843.125000  41751.121094  45576.902344  45171.972656  \n",
       "3449  1921.410034  56840.734375  42134.691406  48257.421875  49596.683594  \n",
       "3450  1766.380859  56821.921875  42345.035156  48394.308594  48461.753906  \n",
       "\n",
       "[3381 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series(data, look_back=60, index_of_column_to_predict=0):\n",
    "    temp = data.copy()\n",
    "    temp[\"id\"] = range(1, len(temp) +1)\n",
    "    temp = temp.iloc[:look_back, :]\n",
    "    temp.set_index('id', inplace = True)\n",
    "    pred_value = data.copy()\n",
    "    pred_value = pred_value.iloc[look_back:, index_of_column_to_predict]\n",
    "    pred_value.columns = [\"Pred\"]\n",
    "    pred_value = pd.DataFrame(pred_value)\n",
    "    \n",
    "    pred_value[\"id\"] =range(1, len(pred_value) +1 )\n",
    "    pred_value.set_index('id', inplace = True)\n",
    "    final_df =pd.concat([temp, pred_value], axis=1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookBack = 60\n",
    "\n",
    "arr_df = create_time_series(values, lookBack, tek_ind_1_copy.columns.get_loc(\"close\"))\n",
    "arr_df.fillna(0, inplace=True)\n",
    "\n",
    "arr_df.columns = ['v1(t-60)','v2(t-60)','v3(t-60)','v4(t-60)','v5(t-60)','v6(t-60)',\n",
    "                  'v7(t-60)','v8(t-60)','v9(t-60)','v10(t-60)','v11(t-60)','v12(t-60)',\n",
    "                  'v13(t-60)','v14(t-60)','v15(t-60)','v16(t-60)','v17(t-60)','v18(t-60)',\n",
    "                  'v19(t-60)','v20(t-60)','v21(t-60)','v22(t-60)', 'v1(t)']\n",
    "\n",
    "print(arr_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train sets\n",
    "val = arr_df.values\n",
    "train_sample = int(len(tek_ind_1_copy) * 0.8)\n",
    "\n",
    "train = pd.DataFrame(val[: train_sample, :])\n",
    "test = pd.DataFrame(val[train_sample:, :])\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(train)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , y_train= [], []\n",
    "for i in range (lookBack, X.shape[0]):\n",
    "    X_train.append(X[i-60: i])\n",
    "    y_train.append(X[i, 0])\n",
    "    if i <= 61:\n",
    "        print(X_train)\n",
    "        print ('\\n')\n",
    "        print (y_train)\n",
    "        print()\n",
    "        \n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim = 22\n",
    "# hidden_dim = 75\n",
    "# num_layers = 3\n",
    "# output_dim = 1\n",
    "# num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# x_train = torch.from_numpy(X_train).type(torch.Tensor)\n",
    "# x_test = torch.from_numpy(X_test).type(torch.Tensor)\n",
    "# y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "# y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "# y_train_gru = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "# y_test_gru = torch.from_numpy(y_test).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = train.tail(60)\n",
    "data = look_back.append(test)\n",
    "print (data)\n",
    "\n",
    "inputs = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test , y_test= [], []\n",
    "for i in range(lookBack, inputs.shape[0]):\n",
    "    X_test.append(inputs[i-lookBack: i])\n",
    "    y_test.append(inputs[i,0])\n",
    "    if i <= 61:\n",
    "        print(X_test)\n",
    "        print ('\\n')\n",
    "        print (y_test)\n",
    "        print()\n",
    "        \n",
    "\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model_lstm = tf.keras.Sequential()\n",
    "model_lstm.add(tf.keras.layers.LSTM(units=75, return_sequences =True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_lstm.add(tf.keras.layers.LSTM(units=30, return_sequences =True))\n",
    "model_lstm.add(tf.keras.layers.LSTM(units=30, return_sequences =True))\n",
    "\n",
    "model_lstm.add(tf.keras.layers.Dense(units=1))\n",
    "model_lstm.compile(loss='mae', optimizer='adam')\n",
    "model_lstm.summary()\n",
    "\n",
    "history_lstm = model_lstm.fit(X_train, y_train, epochs =35, batch_size=32, validation_data =(X_test, y_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_lstm.history['loss'], label ='train_loss', color='red')\n",
    "plt.plot(history_lstm.history['val_loss'], label ='test_loss', color='blue')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model_lstm.predict(X_test)\n",
    "# scaler.scale_\n",
    "# normal_scale = 1/5.21225901e-05\n",
    "# y_pred = y_pred * normal_scale\n",
    "# y_test = y_test * normal_scale\n",
    "\n",
    "# mean_y_test = y_test.mean()\n",
    "# mean_y_pred = y_pred.mean()\n",
    "\n",
    "# print(mean_y_test, mean_y_pred)\n",
    "# accuracy = round((mean_y_test/mean_y_pred )*100, 2)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model_gru = tf.keras.Sequential()\n",
    "model_gru.add(tf.keras.layers.GRU(units=75, return_sequences =True,input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model_gru.add(tf.keras.layers.GRU(units=30, return_sequences =True))\n",
    "model_gru.add(tf.keras.layers.GRU(units=30))\n",
    "model_gru.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "model_gru.compile(loss='mae', optimizer='adam')\n",
    "model_gru.summary()\n",
    "\n",
    "history_gru = model_gru.fit(X_train, y_train, epochs =20, batch_size=64, validation_data =(X_test, y_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_gru.history['loss'], label ='train_loss', color='red')\n",
    "plt.plot(history_gru.history['val_loss'], label ='test_loss', color='blue')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_gru.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.scale_\n",
    "# normal_scale = 1/5.21225901e-05\n",
    "\n",
    "# y_pred = y_pred * normal_scale\n",
    "# y_test = y_test * normal_scale\n",
    "\n",
    "# mean_y_test = y_test.mean()\n",
    "# mean_y_pred = y_pred.mean()\n",
    "\n",
    "# print(mean_y_test, mean_y_pred)\n",
    "# accuracy = round((mean_y_test/mean_y_pred )*100, 2)\n",
    "# accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 23\n",
    "hidden_dim = 32\n",
    "num_layers = 3\n",
    "output_dim = 1\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x_train = torch.from_numpy(X_train).type(torch.Tensor)\n",
    "x_test = torch.from_numpy(X_test).type(torch.Tensor)\n",
    "y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "y_train_gru = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "y_test_gru = torch.from_numpy(y_test).type(torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn) = self.gru(x, (h0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "hist = np.zeros(num_epochs)\n",
    "start_time = time.time()\n",
    "lstm = []\n",
    "for t in range(num_epochs):\n",
    "    y_train_pred = model(x_train)\n",
    "    loss = criterion(y_train_pred, y_train_lstm)\n",
    "    print(\"Epoch \", t, \"Mean Squared Error: \", loss.item())\n",
    "    hist[t] = loss.item()\n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    \n",
    "training_time = time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(y_pred.detach().numpy(), label ='pred')\n",
    "plt.plot(y_test, label ='actual')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
